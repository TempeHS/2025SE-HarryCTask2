{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "This is a demonstration of evaluating a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1\n",
    "\n",
    "Load the required dependencies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import frameworks\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('../style_Matplotlib_charts.mplstyle')\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 9. Multiple Variable Linear Regression\n",
    "\n",
    "Loading the multi-variable linear regression model for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'PolynomialRegression_Models/A_PR_model_v6.sav'\n",
    "model_C = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening and parsing the test data CSV file, with the specific input features collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_test = ['value_score', 'tot_rooms', 'ds_float', 'suburb_lat', 'suburb_lng']\n",
    "testing_data = pd.read_csv('A_testing_data_new_2.csv')\n",
    "mx_test = np.array(testing_data[poly_features])\n",
    "my_test = np.array(testing_data['Target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 10\n",
    "\n",
    "- Individually plotting test data features, targets and predictions from the model, on a graph for each input feature, with the purpose of visually evaluating the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 5 features, but LinearRegression is expecting 461 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m my_pred = \u001b[43mmodel_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmx_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# plot predictions and targets vs original features    \u001b[39;00m\n\u001b[32m      4\u001b[39m fig,ax=plt.subplots(\u001b[32m1\u001b[39m,\u001b[38;5;28mlen\u001b[39m(mx_test),figsize=(\u001b[32m12\u001b[39m,\u001b[32m3\u001b[39m),sharey=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/linear_model/_base.py:297\u001b[39m, in \u001b[36mLinearModel.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    284\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[33;03m    Predict using the linear model.\u001b[39;00m\n\u001b[32m    286\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    295\u001b[39m \u001b[33;03m        Returns predicted values.\u001b[39;00m\n\u001b[32m    296\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/linear_model/_base.py:276\u001b[39m, in \u001b[36mLinearModel._decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    274\u001b[39m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcoo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    277\u001b[39m     coef_ = \u001b[38;5;28mself\u001b[39m.coef_\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m coef_.ndim == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2965\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2962\u001b[39m     out = X, y\n\u001b[32m   2964\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m2965\u001b[39m     \u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2967\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2829\u001b[39m, in \u001b[36m_check_n_features\u001b[39m\u001b[34m(estimator, X, reset)\u001b[39m\n\u001b[32m   2826\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   2828\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_features != estimator.n_features_in_:\n\u001b[32m-> \u001b[39m\u001b[32m2829\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2830\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2831\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator.n_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m features as input.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2832\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: X has 5 features, but LinearRegression is expecting 461 features as input."
     ]
    }
   ],
   "source": [
    "my_pred = model_C.predict(mx_test)\n",
    "\n",
    "# plot predictions and targets vs original features    \n",
    "fig,ax=plt.subplots(1,len(mx_test),figsize=(12,3),sharey=True)\n",
    "for i in range(len(ax)):\n",
    "    ax[i].scatter(mx_test[:,i],my_test, label = 'target')\n",
    "    ax[i].set_xlabel(mx_test[i])\n",
    "    ax[i].scatter(mx_test[:,i],my_pred,color=\"orange\", label = 'predict')\n",
    "    ax[i].set_ylabel(\"Target\"); ax[i].legend();\n",
    "fig.suptitle(\"Diabetes Disease Progress\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 11\n",
    "\n",
    "- Predict the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data score: 0.419107384182133\n"
     ]
    }
   ],
   "source": [
    "test_score = model_C.score(mx_test, my_test)\n",
    "print(f'Training data score: {test_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is quite a low score, though already higher than polynomial and linear regression algorithms, there are improvements which can be made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 11\n",
    "\n",
    "- You can do predictions to get a feel for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-513284.3344197]\n"
     ]
    }
   ],
   "source": [
    "print(model_C.predict([[0.1,0.1,0.1, 0.1, 0.1, 0.1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 12 \n",
    "\n",
    "- Manually calculating the loss and cost of the model using testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      num_bed  num_bath  property_size  value_score  tot_rooms  \\\n",
      "0         3.0       1.0       0.434959     0.176236        4.0   \n",
      "1         3.0       1.0       0.507317     0.369173        4.0   \n",
      "2         5.0       3.0       0.558537     0.426005        8.0   \n",
      "3         4.0       1.0       0.450407     0.249957        5.0   \n",
      "4         3.0       2.0       0.502439     0.389032        5.0   \n",
      "...       ...       ...            ...          ...        ...   \n",
      "2329      2.0       1.0       0.355285     0.314162        3.0   \n",
      "2330      5.0       3.0       0.378049     0.322278        8.0   \n",
      "2331      4.0       3.0       0.450407     0.352563        7.0   \n",
      "2332      5.0       4.0       0.565041     0.406127        9.0   \n",
      "2333      5.0       3.0       0.444715     0.253907        8.0   \n",
      "\n",
      "      suburb_median_income   Target  Predicted result       Cost  \n",
      "0                  25844.0   537000      5.433852e+03  531566.15  \n",
      "1                  38792.0  1150000      1.365840e+06 -215840.27  \n",
      "2                  42172.0  2118000      2.279105e+06 -161104.67  \n",
      "3                  37024.0   610000      7.733519e+05 -163351.91  \n",
      "4                  38792.0  1160000      1.825092e+06 -665092.27  \n",
      "...                    ...      ...               ...        ...  \n",
      "2329               34528.0  1460000      1.405770e+06   54230.27  \n",
      "2330               38584.0  1780000      2.136505e+06 -356505.49  \n",
      "2331               49296.0  1916000      2.464415e+06 -548414.53  \n",
      "2332               43784.0  2100000      2.521392e+06 -421392.31  \n",
      "2333               33228.0  1040000      1.320912e+06 -280911.50  \n",
      "\n",
      "[2334 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "data = {col: mx_test[:, i] for i, col in enumerate(mx_col)}\n",
    "data['Target'] = my_test\n",
    "data['Predicted result'] = model_C.predict(mx_test)\n",
    "data['Cost'] = my_test - model_C.predict(mx_test).round(2)\n",
    "\n",
    "table = pd.DataFrame(data)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows the x axis intercepts, which are the values when inputs are 0 and the coefficients which is the influence a feature has on the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Axis intercept: -795725.0294041773\n",
      "Coefficient: [-1.16143017e+05  2.20660965e+05 -3.32049776e+06  5.93583364e+06\n",
      "  1.04517948e+05  3.51736449e+01]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mX Axis intercept: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_C.intercept_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mCoefficient: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcoef_\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m(\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "print(f'X Axis intercept: {model_C.intercept_}')\n",
    "print(f'Coefficient: {model_C.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The differences in coefficients illuminate how the different input features  influence the model, features like value_score have a high coefficient meaning they have a large influence on the model prediction, while others have quite low predicitons or even negative ones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
