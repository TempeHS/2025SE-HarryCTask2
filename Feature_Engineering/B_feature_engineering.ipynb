{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering\n",
    "\n",
    "The following are data engineering processes to improve the performance of the machine learning model\n",
    "\n",
    "- Features willl be contrived based off features or modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "This Jupyter Notepad is a selection of data engineering processes you can apply to your data before model training to maximise the performance of your machine learning model. For this demonstration we will engineer new or improved features for the diabetes data you previously wrangled.\n",
    "\n",
    "#### Feature Engineering Process\n",
    "- Deriving new variables from existing ones\n",
    "    - Encoding categorical features\n",
    "    - Calculating new features from existing features\n",
    "- Combining features/feature interactions\n",
    "- Identifying the most relevant features for the model\n",
    "- Transforming Features\n",
    "  - [Dividing Data into categories](https://web.ma.utexas.edu/users/mks/statmistakes/dividingcontinuousintocategories.html)\n",
    "  - Mathematical transformations (for example logarithmic transformations). Logarithmic transformations are a powerful tool in the world of statistical analysis. They are often used to transform data that exhibit skewness or other irregularities, making it easier to analyze, visualize, and interpret the results.\n",
    "- Creating Domain-Specific Features that incorporating knowledge from the specific domain to create features that capture important characteristics of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import frameworks\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing data as a local variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(\"wrangled_data_1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Deriving new variables from existing ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encoding categorical variables\n",
    "\n",
    "Data Encoding converts textual data into numerical format, so that it can be used as input for algorithms to process. The reason for encoding is that most machine learning algorithms work with numbers and not with text or categorical variables.\n",
    "\n",
    "I will be encoding the type of property column, assigning the value -1 to an apartment and 1 to house. -1 is a better for choice over 0, as computers will default to 0 more allowing for bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10013    1\n",
      "10014    1\n",
      "10015   -1\n",
      "10016    1\n",
      "10017    1\n",
      "Name: type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_frame['type'] = data_frame['type'].apply(lambda type: -1 if type == 'Apartment' else 1 if type == 'House' else None)\n",
    "print(data_frame['type'].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting date sold into datetime\n",
    "\n",
    "- Ultimately a large factor in determining the sale price of the house is when it was sold. The dates given are strings and must be converted to datetime to increase the performance of the machine learning model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       date_sold      ds_float\n",
      "0     2016-01-13  1.452643e+09\n",
      "1     2016-01-13  1.452643e+09\n",
      "2     2016-01-13  1.452643e+09\n",
      "3     2016-01-15  1.452816e+09\n",
      "4     2016-01-15  1.452816e+09\n",
      "...          ...           ...\n",
      "10013 2021-12-31  1.640909e+09\n",
      "10014 2021-12-31  1.640909e+09\n",
      "10015 2021-12-31  1.640909e+09\n",
      "10016 2022-01-01  1.640995e+09\n",
      "10017 2022-01-01  1.640995e+09\n",
      "\n",
      "[10018 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert date_sold to datetime\n",
    "data_frame['date_sold'] = pd.to_datetime(data_frame['date_sold'], format='%d/%m/%y')\n",
    "\n",
    "#Converting datetime to a float\n",
    "data_frame['ds_float'] = data_frame['date_sold'].astype(int) / 10**9\n",
    "\n",
    "# Print the result\n",
    "print(data_frame[['date_sold', 'ds_float']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining features/feature interactions\n",
    "\n",
    "While individual features can be powerful predictors, their interactions often carry even more information. Feature interaction engineering is the process of creating new features that represent the interaction between two or more features.\n",
    "\n",
    "In this case, domain knowledge is required, so feature interactions could include \n",
    "\n",
    "- Total Numbers of Rooms\n",
    "- Property size x distance from CBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       tot_rooms  value_score\n",
      "0              6     0.431332\n",
      "1              6     0.269558\n",
      "2              4     0.120461\n",
      "3              4     0.272616\n",
      "4              4     0.223928\n",
      "...          ...          ...\n",
      "10013          7     0.148172\n",
      "10014         10     0.305451\n",
      "10015          4     0.000009\n",
      "10016          6     0.109405\n",
      "10017          5     0.384657\n",
      "\n",
      "[10018 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total number of rooms\n",
    "data_frame['tot_rooms'] = (data_frame['num_bath'] + data_frame['num_bed']).astype(int)\n",
    "\n",
    "# Calculating property size x distance from CBD\n",
    "data_frame['value_score'] = data_frame['property_size'] * (data_frame['km_from_cbd'])\n",
    "\n",
    "\n",
    "# Print the result\n",
    "print(data_frame[['tot_rooms', 'value_score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transoforming features\n",
    "\n",
    "Filtering is like applying the where clause in a database. It is widely used and can help when you need to work on a specific subset of your data. ]\n",
    "\n",
    "From my domain knowledge, it is important to delineate that pricing for houses and apartment are very different and cannot be encompassed by a single model. Thus,\n",
    "\n",
    "- Dataset A will only include data rows that are houses\n",
    "- Dataset B will only include data rows that are apartments\n",
    "\n",
    "This is representative of the two seperate models I will have, where one will predict apartment prices and the other hosue prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       date_sold  type   Target\n",
      "23    2016-01-22    -1   272500\n",
      "71    2016-02-22    -1   595000\n",
      "104   2016-02-29    -1   755000\n",
      "148   2016-03-24    -1   730000\n",
      "158   2016-03-30    -1   900000\n",
      "...          ...   ...      ...\n",
      "9951  2021-12-22    -1  1075000\n",
      "9959  2021-12-22    -1   670000\n",
      "9986  2021-12-24    -1  3975000\n",
      "10006 2021-12-28    -1  1510000\n",
      "10015 2021-12-31    -1  1025000\n",
      "\n",
      "[682 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter the data to -1 (Apartment)\n",
    "data_frame = data_frame[data_frame['type'] == -1]\n",
    "\n",
    "# Print the result\n",
    "print(data_frame[['date_sold', 'type', 'Target']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Domain-Specific Features\n",
    "\n",
    "Domain knowledge is about understanding the domain or subject area of the data. In this case the domain is 'real estate'\n",
    "\n",
    "- Possible features could include \n",
    "\n",
    "1. Parking Availability (Binary yes or no)\n",
    "\n",
    "2. Socioeconomic features such as median income of Suburb (Implemented)\n",
    "\n",
    "3. Flood risk (particularly pertinent as a lot of houses bult on flood plains)\n",
    "\n",
    "4. Using an API to gather nearby median house price of suburb lat and long\n",
    "\n",
    "5. Amount of public infrastructure surrounding (can increase property value)\n",
    "\n",
    "6. The cash/interest rate at the time, can increase property value\n",
    "\n",
    "However, there is a sufficient amount of features currently, so the implementation of such features at the moment would be futile, though will be reconisdered after further testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the wrangled and engineered data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.to_csv('../B_Model_Training/model_ready_data/B_model_ready_data_new_1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
